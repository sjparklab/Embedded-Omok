#!/usr/bin/env python3
# train_supervised.py
# Supervised pretraining of policy head on examples generated by generate_ab_games.py
# Trains the entire network but loss only uses policy (optionally add value).

import argparse
import pickle
import os
from torch.utils.data import Dataset, DataLoader
import torch
import torch.nn.functional as F
from torch import optim
from alphazero_model import AlphaZeroNet
from tqdm import tqdm
import numpy as np

class PolicyDataset(Dataset):
    def __init__(self, examples):
        # examples: list of tuples (state_planes (2,H,W), pi (flat H*W), z)
        self.examples = examples
    def __len__(self):
        return len(self.examples)
    def __getitem__(self, idx):
        s, pi, z = self.examples[idx]
        return torch.from_numpy(s).float(), torch.from_numpy(pi).float()

def train_supervised(examples_path="examples_ab.pkl", out_path="checkpoints/supervised_pretrain.pt",
                     epochs=5, batch_size=256, lr=1e-3, board_size=19, num_filters=128, use_amp=False, device='cuda'):
    print("Loading examples...", examples_path)
    with open(examples_path, "rb") as f:
        examples = pickle.load(f)
    print(f"Loaded {len(examples)} examples")

    ds = PolicyDataset(examples)
    dl = DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)

    device = torch.device(device if torch.cuda.is_available() else "cpu")
    net = AlphaZeroNet(board_size=board_size, num_filters=num_filters).to(device)

    opt = optim.Adam(net.parameters(), lr=lr, weight_decay=1e-4)
    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)

    os.makedirs(os.path.dirname(out_path) or ".", exist_ok=True)

    for epoch in range(1, epochs+1):
        net.train()
        total_loss = 0.0
        pbar = tqdm(dl, desc=f"Epoch {epoch}/{epochs}")
        for s_batch, pi_batch in pbar:
            s_batch = s_batch.to(device, non_blocking=True)
            pi_batch = pi_batch.to(device, non_blocking=True)
            with torch.cuda.amp.autocast(enabled=use_amp):
                logits, _ = net(s_batch)  # logits shape (B, H*W)
                logp = F.log_softmax(logits, dim=1)
                loss = - (logp * pi_batch).sum(dim=1).mean()
            scaler.scale(loss).backward()
            scaler.step(opt)
            scaler.update()
            opt.zero_grad()
            total_loss += float(loss.item())
            pbar.set_postfix(loss=total_loss / (pbar.n + 1))
        # checkpoint per epoch
        torch.save({'model': net.state_dict(), 'opt': opt.state_dict(), 'epoch': epoch}, f"{out_path}.epoch{epoch}")
        print(f"Epoch {epoch} saved -> {out_path}.epoch{epoch}")

    # final save
    torch.save({'model': net.state_dict(), 'opt': opt.state_dict(), 'epoch': epochs}, out_path)
    print("Supervised pretraining finished. Model saved to", out_path)
    return out_path

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--examples", type=str, default="examples_ab.pkl")
    parser.add_argument("--out", type=str, default="checkpoints/supervised_pretrain.pt")
    parser.add_argument("--epochs", type=int, default=5)
    parser.add_argument("--batch_size", type=int, default=256)
    parser.add_argument("--lr", type=float, default=1e-3)
    parser.add_argument("--board_size", type=int, default=19)
    parser.add_argument("--num_filters", type=int, default=128)
    parser.add_argument("--use_amp", action="store_true")
    parser.add_argument("--device", type=str, default="cuda")
    args = parser.parse_args()
    train_supervised(examples_path=args.examples, out_path=args.out, epochs=args.epochs,
                     batch_size=args.batch_size, lr=args.lr, board_size=args.board_size,
                     num_filters=args.num_filters, use_amp=args.use_amp, device=args.device)